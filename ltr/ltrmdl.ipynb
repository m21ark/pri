{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Name': 'Kiko Goat', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=1.675411,queryMatchMigratory=0.0,queryMatchText=0.47909436,originalScore=530.3125'}, {'Name': 'Grouse', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.48193377,originalScore=8.499506'}, {'Name': 'Sidewinder', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47588998,originalScore=8.481009'}, {'Name': 'Mouse Deer Chevrotain', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=1.6180977,queryMatchMigratory=0.0,queryMatchText=0.47838327,originalScore=8.472482'}, {'Name': 'Tiger Swallowtail', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.4790273,originalScore=8.440247'}, {'Name': 'Kit Fox', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47955552,originalScore=8.433029'}, {'Name': 'Asiatic Black Bear', '[features]': 'queryMatchName=3.364737,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=1.6760595,queryMatchMigratory=0.0,queryMatchText=0.4755122,originalScore=8.431435'}, {'Name': 'Northern Bobwhite', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47830895,originalScore=8.427036'}, {'Name': 'Patagonian Mara', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=1.2204111,queryMatchMigratory=0.0,queryMatchText=0.47699824,originalScore=8.416769'}, {'Name': 'Bobcat', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.4790273,originalScore=8.408819'}, {'Name': 'Crane', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47816047,originalScore=8.399884'}, {'Name': 'Newt', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=1.4417654,queryMatchMigratory=0.0,queryMatchText=0.48247537,originalScore=8.392608'}, {'Name': 'Eastern Woodrat', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47579548,originalScore=8.384094'}, {'Name': 'Pea Puffer', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47425604,originalScore=8.381737'}, {'Name': 'Parrot', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47551218,originalScore=8.37637'}, {'Name': 'Spixs Macaw', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47801206,originalScore=8.361436'}, {'Name': 'Spider', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47786373,originalScore=8.340939'}, {'Name': 'Comet Moth', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=1.62761,queryMatchMigratory=0.0,queryMatchText=0.47442034,originalScore=8.328259'}, {'Name': 'Chimpanzee', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.4736544,originalScore=8.323116'}, {'Name': 'Hawaiian Crow', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.4753235,originalScore=8.322398'}, {'Name': 'African Tree Toad', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47845754,originalScore=8.307614'}, {'Name': 'Goliath Frog', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47420126,originalScore=8.306265'}, {'Name': 'Bee Eater', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47431076,originalScore=8.29945'}, {'Name': 'Swallowtail Caterpillar', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=1.3941231,queryMatchMigratory=0.0,queryMatchText=0.47733083,originalScore=8.289399'}, {'Name': 'Baboon', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47708133,originalScore=8.289338'}, {'Name': 'Woodlouse', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47603184,originalScore=8.285686'}, {'Name': 'Strawberry Hermit Crab', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=1.6063626,queryMatchMigratory=0.0,queryMatchText=0.47094807,originalScore=8.28236'}, {'Name': 'Tiger Swallowtail Caterpillar', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47570103,originalScore=8.277177'}, {'Name': 'Blobfish', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=0.0,queryMatchMigratory=0.0,queryMatchText=0.47708133,originalScore=8.27511'}, {'Name': 'Woodlouse Spider', '[features]': 'queryMatchName=0.0,queryMatchGenus=0.0,queryMatchClass=0.0,queryMatchOrigin=0.0,queryMatchFun_Fact=1.6354214,queryMatchMigratory=0.0,queryMatchText=0.47458482,originalScore=8.274531'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def send_solr_request(q):\n",
    "    url = \"http://localhost:8983/solr/animals/query\"\n",
    "    \n",
    "    # Define the query parameters\n",
    "    params = {\n",
    "        'q': q,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"Name^2.5 Features^2.0 Fun_Fact^2.0 Diet^2.0 Text^1.5 Features^2.0 Behavior^2.0\",\n",
    "        \"pf\": \"Name^2.5 Features^2.0 Fun_Fact^2.0 Diet^2.0 Text^1.5 Features^2.0 Behavior^2.0\",\n",
    "        \"mm\": \"3<-25%\",\n",
    "        \"ps\": 5,\n",
    "        'rq': '{!ltr model=animals_model efi.text=\\'natural habitat\\'}',\n",
    "        'fl': 'id,Name,score,[features]',\n",
    "        \"rows\": \"30\"\n",
    "\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Send the HTTP GET request\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Print the response content\n",
    "            # print(\"Response:\")\n",
    "            return (response.json())\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def parse_solr_response(response_json):\n",
    "    # Extract the list of animals from the Solr response\n",
    "    animals = []\n",
    "\n",
    "    # Check if 'response' and 'docs' keys exist in the response\n",
    "    if 'response' in response_json and 'docs' in response_json['response']:\n",
    "        for doc in response_json['response']['docs']:\n",
    "            # Check if 'Name' and 'score' keys exist in the document\n",
    "            if 'Name' in doc and 'score' in doc:\n",
    "                animal = {\n",
    "                    'Name': doc['Name'],\n",
    "                    '[features]': doc['[features]']\n",
    "                }\n",
    "                animals.append(animal)\n",
    "\n",
    "    return animals\n",
    "\n",
    "res = send_solr_request('natural habitat')\n",
    "\n",
    "print (parse_solr_response(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json as simplejson\n",
    "\n",
    "queries = [\"Energetic dog breeds suited for hunting\",\n",
    "\"North America animals that like to eat insects\",\n",
    "\"Change the color of their skin, fur or feathers for the purpose of camouflage\",\n",
    "\"Animals that walk in hierarchical groups or herds and how they deal with territory\", \"(NOT Birds) migrate to Mexico or migrate to America\"]\n",
    "\n",
    "for idx, q in enumerate(queries):\n",
    "    res = send_solr_request(q)\n",
    "    animals = parse_solr_response(res)\n",
    "\n",
    "    df = pd.DataFrame(animals)\n",
    "    # df.to_csv('queries/query{0}_results.csv'.format(idx+1), index=False)\n",
    "\n",
    "    # drop every column except the Name \n",
    "    # df = df[df.columns[0:1]]\n",
    "\n",
    "    df['score'] = 0.0\n",
    "\n",
    "    # save the query results to a csv file\n",
    "    # df.to_csv('queries/query{0}_score.csv'.format(idx+1), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Criteria\n",
    "- 0 - A document that does not match the query.\n",
    "- 1 - A document that vaguely matches the query, is very incomplete (missing important fields, like instructions) and has no reviews. Or has very negative reviews.\n",
    "- 2 - A document that partially matches the query, is incomplete. \n",
    "- 3 - A document that matches the query semantically, is reasonably complete (may miss more than two fields) and has at least one positive review.\n",
    "- 4 - A document that perfectly or almost perfectly matches the query semantically, is complete or missing just one of the fields.\n",
    "- 5 - A document that perfectly matches the query semantically, is complete (the recipe has a full ingredient list, steps and cook time/nutritional information).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear model using svm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "result_files = glob.glob(\"queries/*_results_done.csv\")\n",
    "scores_files = glob.glob(\"queries/*_score_done.csv\")\n",
    "\n",
    "result_files.sort()\n",
    "scores_files.sort()\n",
    "\n",
    "inputs = pd.concat((pd.read_csv(file) for file in result_files), ignore_index=True)\n",
    "scores = pd.concat((pd.read_csv(file) for file in scores_files), ignore_index=True)\n",
    "\n",
    "\n",
    "#merge results_files and scores_files into a single data frame called ltr\n",
    "for ind, pair in enumerate(zip(result_files, scores_files)):\n",
    "    result = pd.read_csv(pair[0])\n",
    "    score = pd.read_csv(pair[1])\n",
    "    result['score'] = score['score']\n",
    "    result['Name'] = score['Name']\n",
    "    result.to_csv('queries/query{0}_ltr.csv'.format(ind+1), index=False)\n",
    "\n",
    "X = []\n",
    "Y = [entry.score for entry in scores.itertuples()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(entry):\n",
    "    return [float(feature.split(\"=\")[1]) for feature in entry._2.split(\",\")]\n",
    "\n",
    "\n",
    "for entry in inputs.itertuples():\n",
    "\n",
    "    X.append(get_features(entry))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "(train_x,\n",
    " test_x,\n",
    " train_y,\n",
    " test_y) = train_test_split(X, Y, test_size=0.10, random_state=0)\n",
    "\n",
    " \n",
    "scaler.fit(X)\n",
    "X = scaler.fit_transform(X)\n",
    "best_random_state = None\n",
    "best_r2_score = -1\n",
    "\n",
    "# for random_state in range(0, 100):\n",
    "#     # Split the data using the current random state\n",
    "#     train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.20, random_state=random_state)\n",
    "\n",
    "#     # Perform any necessary preprocessing steps\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(train_x)\n",
    "#     train_x = scaler.transform(train_x)\n",
    "#     test_x = scaler.transform(test_x)\n",
    "\n",
    "#     # Train your model\n",
    "#     model =  svm.LinearSVR()  # Replace YourModel with the actual model you are using\n",
    "#     model.fit(train_x, train_y)\n",
    "\n",
    "#     # Make predictions on the test set\n",
    "#     predictions = model.predict(test_x)\n",
    "\n",
    "#     # Evaluate the model using a suitable metric (e.g., R-squared score)\n",
    "#     r2 = r2_score(test_y, predictions)\n",
    "\n",
    "#     # Update the best random state if necessary\n",
    "#     if r2 > best_r2_score:\n",
    "#         best_r2_score = r2\n",
    "#         best_random_state = random_state\n",
    "\n",
    "# print(\"Best Random State:\", best_random_state)\n",
    "# print(\"Best R-squared Score:\", best_r2_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08454806320262342"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "linearSVM = svm.LinearSVR()\n",
    "lienarReg = linear_model.LinearRegression()\n",
    "\n",
    "linearSVM.fit(train_x, train_y)\n",
    "lienarReg.fit(train_x, train_y)\n",
    "\n",
    "pred_svm = linearSVM.predict(test_x)\n",
    "pred_reg = lienarReg.predict(test_x)\n",
    "\n",
    "r2_score(test_y, pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with all data\n",
    "# linearSVM = svm.LinearSVR()\n",
    "# lienarReg = linear_model.LinearRegression()\n",
    "\n",
    "# linearSVM.fit(X, Y)\n",
    "# lienarReg.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0148142   0.          0.          0.         -0.01010227  0.\n",
      "  0.03712187  0.21099972]\n"
     ]
    }
   ],
   "source": [
    "## print the scores of the features in the model\n",
    "print(linearSVM.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.08421857e-03 -7.49400542e-16  1.12757026e-16  0.00000000e+00\n",
      " -8.19807676e-02  0.00000000e+00 -1.35990977e-01  2.10821428e-02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.06585008112627277"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lienarReg.coef_)\n",
    "\n",
    "## score of linear regression\n",
    "r2_score(test_y, pred_reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
